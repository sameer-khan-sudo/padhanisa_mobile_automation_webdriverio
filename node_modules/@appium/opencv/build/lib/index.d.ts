export type MatchComputationResult = {
    /**
     * - OpenCV match descriptor
     */
    descriptor: OpenCVBindings["Mat"];
    /**
     * - The array of key points
     */
    keyPoints: OpenCVBindings["KeyPointVector"];
};
export type MatchingOptions = {
    /**
     * One of possible OpenCV feature detector names
     * from keys of the `AVAILABLE_DETECTORS` object.
     * Some of these methods (FAST, AGAST, GFTT, FAST, SIFT and MSER) are not available
     * in the default OpenCV installation and have to be enabled manually before
     * library compilation.
     */
    detectorName?: string | undefined;
    /**
     * The name of the matching function.
     * Should be one of the keys of the `AVAILABLE_MATCHING_FUNCTIONS` object.
     */
    matchFunc?: string | undefined;
    /**
     * The maximum count of "good" matches
     * (e. g. with minimal distances) or a function, which accepts 3 arguments: the current distance,
     * minimal distance, maximum distance and returns true or false to include or exclude the match.
     */
    goodMatchesFactor?: number | Function | null | undefined;
    /**
     * Whether to return the resulting visalization
     * as an image (useful for debugging purposes)
     */
    visualize?: boolean | undefined;
};
export type MatchingResult = {
    /**
     * The count of matched edges on both images.
     * The more matching edges there are no both images the more similar they are.
     */
    count: number;
    /**
     * The total count of matched edges on both images.
     * It is equal to `count` if `goodMatchesFactor` does not limit the matches,
     * otherwise it contains the total count of matches before `goodMatchesFactor` is
     * applied.
     */
    totalCount: number;
    /**
     * The visualization of the matching result
     * represented as PNG image buffer. This visualization looks like
     * https://user-images.githubusercontent.com/31125521/29702731-c79e3142-8972-11e7-947e-db109d415469.jpg
     */
    visualization?: Buffer<ArrayBufferLike> | null | undefined;
    /**
     * The array of matching points on the first image
     */
    points1: Point[];
    /**
     * The bounding rect for the `matchedPoints1` set or a zero rect
     * if not enough matching points are found
     */
    rect1: Rect;
    /**
     * The array of matching points on the second image
     */
    points2: Point[];
    /**
     * The bounding rect for the `matchedPoints2` set or a zero rect
     * if not enough matching points are found
     */
    rect2: Rect;
};
export type SimilarityOptions = {
    /**
     * Whether to return the resulting visalization
     * as an image (useful for debugging purposes)
     */
    visualize?: boolean | undefined;
    /**
     * The name of the template matching method.
     * Acceptable values are:
     * - `TM_CCOEFF`
     * - `TM_CCOEFF_NORMED` (default)
     * - `TM_CCORR`
     * - `TM_CCORR_NORMED`
     * - `TM_SQDIFF`
     * - `TM_SQDIFF_NORMED`
     * Read https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_template_matching/py_template_matching.html
     * for more details.
     */
    method?: string | undefined;
};
export type SimilarityResult = {
    /**
     * The similarity score as a float number in range [0.0, 1.0].
     * 1.0 is the highest score (means both images are totally equal).
     */
    score: number;
    /**
     * The visualization of the matching result
     * represented as PNG image buffer. This image includes both input pictures where
     * difference regions are highlighted with rectangles.
     */
    visualization?: Buffer<ArrayBufferLike> | null | undefined;
};
export type OccurrenceOptions = {
    /**
     * Whether to return the resulting visalization
     * as an image (useful for debugging purposes)
     */
    visualize?: boolean | undefined;
    /**
     * At what normalized threshold to reject
     * a match
     */
    threshold?: number | undefined;
    /**
     * find multiple matches in the image
     */
    multiple?: number | boolean | undefined;
    /**
     * The pixel distance between matches we consider
     * to be part of the same template match
     */
    matchNeighbourThreshold?: number | undefined;
    method?: TemplateMatchingMethod | undefined;
};
export type OccurrenceResult = {
    /**
     * The region of the partial image occurence
     * on the full image
     */
    rect: import("@appium/types").Rect;
    /**
     * The visualization of the matching result
     * represented as PNG image buffer. On this image the matching
     * region is highlighted with a rectangle. If the multiple option is passed,
     * all results are highlighted here.
     */
    visualization?: Buffer<ArrayBufferLike> | null | undefined;
    /**
     * The similarity score as a float number in range [0.0, 1.0].
     * 1.0 is the highest score (means both images are totally equal).
     */
    score: number;
    /**
     * The array of matching OccurenceResults
     * - only when multiple option is passed
     */
    multiple?: OccurrenceResult[] | undefined;
    /**
     * The name of the template matching method.
     * Acceptable values are:
     * - `TM_CCOEFF`
     * - `TM_CCOEFF_NORMED` (default)
     * - `TM_CCORR`
     * - `TM_CCORR_NORMED`
     * - `TM_SQDIFF`
     * - `TM_SQDIFF_NORMED`
     * Read https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_template_matching/py_template_matching.html
     * for more details.
     */
    method?: TemplateMatchingMethod | undefined;
};
export type Match = {
    score: number;
    x: number;
    y: number;
};
export type Region = {
    /**
     * - The offset from the left side
     */
    left: number;
    /**
     * - The offset from the top
     */
    top: number;
    /**
     * - The width
     */
    width: number;
    /**
     * - The height
     */
    height: number;
};
export type Point = {
    /**
     * - The x coordinate
     */
    x: number;
    /**
     * - The y coordinate
     */
    y: number;
};
export type Rect = {
    /**
     * - The top left coordinate
     */
    x: number;
    /**
     * - The bottom right coordinate
     */
    y: number;
    /**
     * - The width
     */
    width: number;
    /**
     * - The height
     */
    height: number;
};
export type OpenCVBindings = {
    Mat: any;
    KeyPointVector: any;
    FeatureDetector: any;
};
export type TemplateMatchingMethod = "TM_CCOEFF" | "TM_CCOEFF_NORMED" | "TM_CCORR" | "TM_CCORR_NORMED" | "TM_SQDIFF" | "TMSQDIFF_NORMED";
/**
 * @typedef MatchingOptions
 * @property {string} [detectorName='ORB'] One of possible OpenCV feature detector names
 * from keys of the `AVAILABLE_DETECTORS` object.
 * Some of these methods (FAST, AGAST, GFTT, FAST, SIFT and MSER) are not available
 * in the default OpenCV installation and have to be enabled manually before
 * library compilation.
 * @property {string} [matchFunc='BruteForce'] The name of the matching function.
 * Should be one of the keys of the `AVAILABLE_MATCHING_FUNCTIONS` object.
 * @property {number|Function?} [goodMatchesFactor] The maximum count of "good" matches
 * (e. g. with minimal distances) or a function, which accepts 3 arguments: the current distance,
 * minimal distance, maximum distance and returns true or false to include or exclude the match.
 * @property {boolean} [visualize=false] Whether to return the resulting visalization
 * as an image (useful for debugging purposes)
 */
/**
 * @typedef MatchingResult
 * @property {number} count The count of matched edges on both images.
 * The more matching edges there are no both images the more similar they are.
 * @property {number} totalCount The total count of matched edges on both images.
 * It is equal to `count` if `goodMatchesFactor` does not limit the matches,
 * otherwise it contains the total count of matches before `goodMatchesFactor` is
 * applied.
 * @property {Buffer?} [visualization] The visualization of the matching result
 * represented as PNG image buffer. This visualization looks like
 * https://user-images.githubusercontent.com/31125521/29702731-c79e3142-8972-11e7-947e-db109d415469.jpg
 * @property {Point[]} points1 The array of matching points on the first image
 * @property {Rect} rect1 The bounding rect for the `matchedPoints1` set or a zero rect
 * if not enough matching points are found
 * @property {Point[]} points2 The array of matching points on the second image
 * @property {Rect} rect2 The bounding rect for the `matchedPoints2` set or a zero rect
 * if not enough matching points are found
 */
/**
 * Calculates the count of common edges between two images.
 * The images might be rotated or resized relatively to each other.
 *
 * @param {Buffer} img1Data The data of the first image packed into a NodeJS buffer
 * @param {Buffer} img2Data The data of the second image packed into a NodeJS buffer
 * @param {MatchingOptions} [options={}] Set of matching options
 *
 * @returns {Promise<MatchingResult>} Maching result
 * @throws {Error} If `detectorName` value is unknown.
 */
export function getImagesMatches(img1Data: Buffer, img2Data: Buffer, options?: MatchingOptions): Promise<MatchingResult>;
/**
 * @typedef SimilarityOptions
 * @property {boolean} [visualize=false] Whether to return the resulting visalization
 * as an image (useful for debugging purposes)
 * @property {string} [method='TM_CCOEFF_NORMED'] The name of the template matching method.
 * Acceptable values are:
 * - `TM_CCOEFF`
 * - `TM_CCOEFF_NORMED` (default)
 * - `TM_CCORR`
 * - `TM_CCORR_NORMED`
 * - `TM_SQDIFF`
 * - `TM_SQDIFF_NORMED`
 * Read https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_template_matching/py_template_matching.html
 * for more details.
 */
/**
 * @typedef SimilarityResult
 * @property {number} score The similarity score as a float number in range [0.0, 1.0].
 * 1.0 is the highest score (means both images are totally equal).
 * @property {Buffer?} [visualization] The visualization of the matching result
 * represented as PNG image buffer. This image includes both input pictures where
 * difference regions are highlighted with rectangles.
 */
/**
 * Calculates the similarity score between two images.
 * It is expected, that both images have the same resolution.
 *
 * @param {Buffer} img1Data The data of the first image packed into a NodeJS buffer
 * @param {Buffer} img2Data The data of the second image packed into a NodeJS buffer
 * @param {SimilarityOptions} [options={}] Set of similarity calculation options
 *
 * @returns {Promise<SimilarityResult>} The calculation result
 * @throws {Error} If the given images have different resolution.
 */
export function getImagesSimilarity(img1Data: Buffer, img2Data: Buffer, options?: SimilarityOptions): Promise<SimilarityResult>;
/**
 * @typedef OccurrenceOptions
 * @property {boolean} [visualize=false] Whether to return the resulting visalization
 * as an image (useful for debugging purposes)
 * @property {number} [threshold=0.5] At what normalized threshold to reject
 * a match
 * @property {number|boolean} [multiple=false] find multiple matches in the image
 * @property {number} [matchNeighbourThreshold=10] The pixel distance between matches we consider
 * to be part of the same template match
 * @property {TemplateMatchingMethod} [method='TM_CCOEFF_NORMED']
 */
/**
 * @typedef OccurrenceResult
 * @property {import('@appium/types').Rect} rect The region of the partial image occurence
 * on the full image
 * @property {Buffer?} [visualization] The visualization of the matching result
 * represented as PNG image buffer. On this image the matching
 * region is highlighted with a rectangle. If the multiple option is passed,
 * all results are highlighted here.
 * @property {number} score The similarity score as a float number in range [0.0, 1.0].
 * 1.0 is the highest score (means both images are totally equal).
 * @property {OccurrenceResult[]} [multiple] The array of matching OccurenceResults
 * - only when multiple option is passed
 * @property {TemplateMatchingMethod} [method='TM_CCOEFF_NORMED'] The name of the template matching method.
 * Acceptable values are:
 * - `TM_CCOEFF`
 * - `TM_CCOEFF_NORMED` (default)
 * - `TM_CCORR`
 * - `TM_CCORR_NORMED`
 * - `TM_SQDIFF`
 * - `TM_SQDIFF_NORMED`
 * Read https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_template_matching/py_template_matching.html
 * for more details.
 */
/**
 * Calculates the occurrence position of a partial image in the full
 * image.
 *
 * @param {Buffer} fullImgData The data of the full image packed into a NodeJS buffer
 * @param {Buffer} partialImgData The data of the partial image packed into a NodeJS buffer
 * @param {OccurrenceOptions} [options] Set of occurrence calculation options
 *
 * @returns {Promise<OccurrenceResult>}
 * @throws {Error} If no occurrences of the partial image can be found in the full image
 */
export function getImageOccurrence(fullImgData: Buffer, partialImgData: Buffer, options?: OccurrenceOptions): Promise<OccurrenceResult>;
/**
 * Spins until the opencv-bindings module is fully loaded
 */
export function initOpenCv(): Promise<void>;
import { Buffer } from 'buffer';
//# sourceMappingURL=index.d.ts.map